{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533df5b3-cdf9-4a2c-b444-ef4018aee3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0e9d4-2079-4c2d-b3c7-14d3fd736f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web scraping refers to the process of extracting data from websites by using automated scripts or programs.It involvesfetching \n",
    "web pages, parsing the HTML or structured data within them, and extracting the desired information for further analysis or use.\n",
    "Web scraping allows you to collect data from various websites at scale, providing access to a vast amount of information that\n",
    " can be utilized for numerous purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8127d-1cc0-4758-b16e-e14bf385a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here are three areas where web scraping is commonly used :-\n",
    "Data Aggregation and Market Research,Content Monitoring and Social Media Analysis,Real Estate and Property Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a72e48-d4da-446d-81b3-5649b3f3b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67d4a1-8afb-4ab2-bd22-ec455712314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are several methods and techniques used for web scraping.\n",
    "Manual Copy-Pasting,Regular Expression (Regex) Matching,HTML Parsing etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189797f-c668-4adb-8a32-f96152cca8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4576dd7-8ba8-49d7-b29c-7517c001d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beautiful Soup is a Python library commonly used for web scraping tasks. It provides a convenient way to parse\n",
    "HTML or XML documents, navigate their structure, and extract data from them. Beautiful Soup simplifies the process\n",
    "of scraping web pages by providing intuitive methods and tools for data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90f233-e844-49f5-9285-95f05aa04fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f0cd8-0eee-4e17-854a-35f919935b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask is a popular web framework in Python, known for its simplicity, flexibility, and ease of use.\n",
    " While Flask is commonly used for building web applications, it can also be beneficial in web scraping projects.\n",
    "Flask allows you to create a web interface or dashboard to interact with your web scraping project.    Flask allows you to create a web interface or dashboard to interact with your web scraping project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d1d0c-5ee9-4185-b914-68add714c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d38a2-9ed1-4e51-98e5-0b920e5149f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a web scraping project, several AWS (Amazon Web Services) services can be used to enhance the infrastructure, storage, and scalability of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a3bb1-99be-4066-a2ee-d417251b0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) Amazon EC2 (Elastic Compute Cloud):\n",
    "Amazon EC2 provides resizable compute capacity in the cloud. It is commonly used to host the web scraping application itself. \n",
    "2)Amazon S3 (Simple Storage Service):\n",
    "Amazon S3 is an object storage service used for storing and retrieving large amounts of data.\n",
    "3)Amazon RDS (Relational Database Service):\n",
    "Amazon RDS provides managed database services, including popular database engines like MySQL, PostgreSQL, or Oracle. \n",
    "4)Amazon DynamoDB:\n",
    "Amazon DynamoDB is a fully managed NoSQL database service. In a web scraping project, DynamoDB can be used to store and retrieve unstructured or semi-structured data extracted during the scraping process.\n",
    "5)Amazon CloudWatch:\n",
    "Amazon CloudWatch is a monitoring and observability service that collects and tracks metrics, logs, and events.\n",
    "6)AWS Lambda:\n",
    "AWS Lambda is a serverless compute service that allows you to run code without provisioning or managing servers.\n",
    "7)Amazon API Gateway:\n",
    "Amazon API Gateway is a fully managed service that makes it easy to create, publish, and manage APIs.\n",
    "80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
